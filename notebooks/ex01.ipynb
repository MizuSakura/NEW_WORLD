{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08961232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    "import yaml\n",
    "import io\n",
    "from pathlib import Path\n",
    "\n",
    "class ScalingZipLoader:\n",
    "    def __init__(self, zip_path):\n",
    "        self.zip_path = Path(zip_path)\n",
    "        if not self.zip_path.exists():\n",
    "            raise FileNotFoundError(f\"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå ZIP: {zip_path}\")\n",
    "\n",
    "        self.scaler_in = None\n",
    "        self.scaler_out = None\n",
    "        self.metadata = None\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"‡πÇ‡∏´‡∏•‡∏î input/output scaler ‡πÅ‡∏•‡∏∞ metadata ‡∏à‡∏≤‡∏Å ZIP\"\"\"\n",
    "        with zipfile.ZipFile(self.zip_path, \"r\") as zipf:\n",
    "            # ‚úÖ ‡πÇ‡∏´‡∏•‡∏î input_scaler.pkl\n",
    "            with zipf.open(\"input_scaler.pkl\") as f:\n",
    "                buffer = io.BytesIO(f.read())\n",
    "                self.scaler_in = joblib.load(buffer)\n",
    "\n",
    "            # ‚úÖ ‡πÇ‡∏´‡∏•‡∏î output_scaler.pkl\n",
    "            with zipf.open(\"output_scaler.pkl\") as f:\n",
    "                buffer = io.BytesIO(f.read())\n",
    "                self.scaler_out = joblib.load(buffer)\n",
    "\n",
    "            # ‚úÖ ‡πÇ‡∏´‡∏•‡∏î metadata.yaml\n",
    "            with zipf.open(\"metadata.yaml\") as f:\n",
    "                self.metadata = yaml.safe_load(f)\n",
    "\n",
    "        print(f\"üì¶ Loaded ZIP successfully: {self.zip_path}\")\n",
    "        return self.scaler_in, self.scaler_out, self.metadata\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # üß™ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
    "    zip_file = r\"D:\\Project_end\\New_world\\my_project\\config\\Test_scale1_scalers.zip\"\n",
    "    loader = ScalingZipLoader(zip_file)\n",
    "    scaler_in, scaler_out, metadata = loader.load()\n",
    "\n",
    "    print(\"\\nüéØ Metadata summary:\")\n",
    "    print(yaml.dump(metadata, allow_unicode=True, sort_keys=False))\n",
    "\n",
    "    # ‚úÖ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô scaler\n",
    "    import numpy as np\n",
    "    sample_input = np.array([[0.5]])\n",
    "    scaled_input = scaler_in.transform(sample_input)\n",
    "    print(\"\\nSample input 0.5 scaled:\", scaled_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905dae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# LSTM RC Tank Prediction Example\n",
    "# -----------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# Load dataset\n",
    "# -----------------------------\n",
    "data_file = r\"D:\\Project_end\\New_world\\my_project\\data\\raw\\pwm_duty_0.56_freq_0.01_pwm.csv\"\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# -----------------------------\n",
    "# Load scalers (‡∏à‡∏≤‡∏Å ZIP ‡∏Å‡πá‡πÑ‡∏î‡πâ)\n",
    "# -----------------------------\n",
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ä‡πâ MinMaxScaler ‡πÉ‡∏´‡∏°‡πà\n",
    "input_features = [\"DATA_INPUT\", \"DATA_OUTPUT\"]\n",
    "output_features = [\"DATA_OUTPUT\"]\n",
    "\n",
    "scaler_in = MinMaxScaler()\n",
    "scaler_out = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_in.fit_transform(df[input_features].values)\n",
    "y_scaled = scaler_out.fit_transform(df[output_features].values)\n",
    "\n",
    "# -----------------------------\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á sequences ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LSTM\n",
    "# -----------------------------\n",
    "window_size = 30\n",
    "\n",
    "def create_sequences(X, y, window_size=30):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(len(X) - window_size):\n",
    "        X_seq.append(X[i:i+window_size])\n",
    "        y_seq.append(y[i+window_size])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_scaled, window_size=window_size)\n",
    "\n",
    "# ‡πÅ‡∏ö‡πà‡∏á train/val/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô torch.Tensor\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á LSTM model\n",
    "# -----------------------------\n",
    "class LSTM_Predictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, output_size=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_size = X_train.shape[2]\n",
    "output_size = y_train.shape[1]\n",
    "\n",
    "model = LSTM_Predictor(input_size=input_size, hidden_size=64, num_layers=2, output_size=output_size)\n",
    "\n",
    "# -----------------------------\n",
    "# Training setup\n",
    "# -----------------------------\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "# -----------------------------\n",
    "# Training loop\n",
    "# -----------------------------\n",
    "for epoch in range(epochs):\n",
    "    permutation = torch.randperm(X_train.size(0))\n",
    "    epoch_loss = 0\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_X, batch_y = X_train[indices], y_train[indices]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "    epoch_loss /= X_train.size(0)\n",
    "    if (epoch+1) % 5 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.6f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Test & Plot\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test).numpy()\n",
    "\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö scale ‡πÄ‡∏î‡∏¥‡∏°\n",
    "y_pred_orig = scaler_out.inverse_transform(y_pred)\n",
    "y_test_orig = scaler_out.inverse_transform(y_test.numpy())\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(y_test_orig, label=\"True Tank Level\")\n",
    "plt.plot(y_pred_orig, label=\"Predicted Tank Level\", alpha=0.7)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.ylabel(\"Tank Level\")\n",
    "plt.title(\"LSTM Prediction RC Tank\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723fcb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Project root added to sys.path: D:\\Project_end\\New_world\\my_project\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# project_root = my_project\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "print(\"‚úÖ Project root added to sys.path:\", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1225aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LSTMForecaster', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'nn', 'torch']\n"
     ]
    }
   ],
   "source": [
    "import src.models.lstm_model\n",
    "print(dir(src.models.lstm_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------------\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á (sin wave)\n",
    "# -----------------------------------\n",
    "T = 100\n",
    "x = torch.linspace(0, 8 * 3.1416, T)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á input-output ‡∏•‡∏≥‡∏î‡∏±‡∏ö\n",
    "seq_len = 5\n",
    "inputs = torch.stack([y[i:i+seq_len] for i in range(T - seq_len)])\n",
    "targets = torch.stack([y[i+seq_len] for i in range(T - seq_len)])\n",
    "\n",
    "inputs = inputs.unsqueeze(-1)  # (batch, seq_len, 1)\n",
    "targets = targets.unsqueeze(-1)  # (batch, 1)\n",
    "\n",
    "# -----------------------------------\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• LSTM ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤\n",
    "# -----------------------------------\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, stateful=False):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.hidden_state = None\n",
    "        self.stateful = stateful\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def reset_state(self, batch_size):\n",
    "        self.hidden_state = (\n",
    "            torch.zeros(1, batch_size, self.hidden_size),\n",
    "            torch.zeros(1, batch_size, self.hidden_size)\n",
    "        )\n",
    "\n",
    "    def detach_state(self):\n",
    "        if self.hidden_state is not None:\n",
    "            self.hidden_state = (self.hidden_state[0].detach(),\n",
    "                                 self.hidden_state[1].detach())\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.stateful and self.hidden_state is not None:\n",
    "            out, self.hidden_state = self.lstm(x, self.hidden_state)\n",
    "        else:\n",
    "            out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# -----------------------------------\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á model 2 ‡πÅ‡∏ö‡∏ö\n",
    "# -----------------------------------\n",
    "model_stateless = SimpleLSTM(1, 32, stateful=False)\n",
    "model_stateful = SimpleLSTM(1, 32, stateful=True)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer1 = torch.optim.Adam(model_stateless.parameters(), lr=0.01)\n",
    "optimizer2 = torch.optim.Adam(model_stateful.parameters(), lr=0.01)\n",
    "\n",
    "losses_stateless = []\n",
    "losses_stateful = []\n",
    "\n",
    "# -----------------------------------\n",
    "# Training ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "# -----------------------------------\n",
    "for epoch in range(10):\n",
    "    # -------- Stateless --------\n",
    "    total_loss = 0\n",
    "    for i in range(len(inputs)):\n",
    "        x_seq = inputs[i].unsqueeze(0)\n",
    "        y_true = targets[i].unsqueeze(0)\n",
    "\n",
    "        optimizer1.zero_grad()\n",
    "        y_pred = model_stateless(x_seq)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    losses_stateless.append(total_loss / len(inputs))\n",
    "\n",
    "    # -------- Stateful --------\n",
    "    total_loss = 0\n",
    "    model_stateful.reset_state(batch_size=1)\n",
    "    for i in range(len(inputs)):\n",
    "        x_seq = inputs[i].unsqueeze(0)\n",
    "        y_true = targets[i].unsqueeze(0)\n",
    "\n",
    "        optimizer2.zero_grad()\n",
    "        y_pred = model_stateful(x_seq)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        model_stateful.detach_state()  # <--- ‡∏ï‡∏±‡∏î‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ï‡πà‡∏à‡∏≥‡∏Ñ‡πà‡∏≤‡πÑ‡∏ß‡πâ\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    losses_stateful.append(total_loss / len(inputs))\n",
    "\n",
    "# -----------------------------------\n",
    "# Plot ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö\n",
    "# -----------------------------------\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(losses_stateless, label='Stateless LSTM')\n",
    "plt.plot(losses_stateful, label='Stateful LSTM (reset/detach)')\n",
    "plt.title('Comparison: Stateless vs Stateful LSTM')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee2324",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup_path.py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==============================\n",
    "# 1Ô∏è‚É£ RC Tank Environment\n",
    "# ==============================\n",
    "class RC_Tank_Env:\n",
    "    def __init__(self, R=1.5, C=2.0, dt=0.1,\n",
    "                 control_mode='voltage', setpoint_level=5.0,\n",
    "                 level_max=10.0, max_action_volt=24.0, max_action_current=5.0):\n",
    "        self.R = R\n",
    "        self.C = C\n",
    "        self.dt = dt\n",
    "        self.mode = control_mode\n",
    "        self.setpoint_level = setpoint_level\n",
    "        self.level_max = level_max\n",
    "        self.max_action_volt = max_action_volt\n",
    "        self.max_action_current = max_action_current\n",
    "        self.level = 0.0\n",
    "        self.time = 0.0\n",
    "\n",
    "    def reset(self, default=0.0):\n",
    "        self.level = float(default)\n",
    "        self.time = 0.0\n",
    "        done = False\n",
    "        return float(self.level), done\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.mode == 'voltage':\n",
    "            action = np.clip(action, 0, self.max_action_volt)\n",
    "            current = (action - self.level) / self.R\n",
    "            delta_level = (current / self.C) * self.dt\n",
    "        elif self.mode == 'current':\n",
    "            action = np.clip(action, 0, self.max_action_current)\n",
    "            net_flow = action - (self.level / self.R)\n",
    "            delta_level = (net_flow / self.C) * self.dt\n",
    "        else:\n",
    "            raise ValueError(\"Invalid control_mode\")\n",
    "        self.level += delta_level\n",
    "        self.level = np.clip(self.level, 0, self.level_max)\n",
    "        self.time += self.dt\n",
    "        done = abs(self.setpoint_level - self.level) <= 0.1\n",
    "        return float(self.level), bool(done)\n",
    "\n",
    "# ==============================\n",
    "# 2Ô∏è‚É£ Signal Generator\n",
    "# ==============================\n",
    "class SignalGenerator:\n",
    "    def __init__(self, t_end=100, dt=0.1):\n",
    "        self.dt = dt\n",
    "        self.t_end = t_end\n",
    "        self.time_array = np.arange(0, t_end, dt)\n",
    "\n",
    "    def pwm(self, amplitude=1.0, freq=1.0, duty=0.5):\n",
    "        T = 1 / freq\n",
    "        signal = amplitude * ((self.time_array % T) < duty * T)\n",
    "        return self.time_array, signal\n",
    "\n",
    "# ==============================\n",
    "# 3Ô∏è‚É£ DeepLSTMRegressor\n",
    "# ==============================\n",
    "class DeepLSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1,\n",
    "                 num_layers=2, fc_units=[128,64], dropout=0.2, stateful=True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.stateful = stateful\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        layers = []\n",
    "        in_features = hidden_size\n",
    "        for u in fc_units:\n",
    "            layers.append(nn.Linear(in_features, u))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            in_features = u\n",
    "        layers.append(nn.Linear(in_features, output_size))\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "        self.hidden_state = None\n",
    "\n",
    "    def reset_state(self, batch_size=1, device=None):\n",
    "        if device is None:\n",
    "            device = next(self.parameters()).device\n",
    "        self.hidden_state = (\n",
    "            torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device),\n",
    "            torch.zeros(self.num_layers, batch_size, self.hidden_size, device=device)\n",
    "        )\n",
    "\n",
    "    def detach_state(self):\n",
    "        if self.hidden_state is not None:\n",
    "            self.hidden_state = (self.hidden_state[0].detach(), self.hidden_state[1].detach())\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.stateful and self.hidden_state is not None:\n",
    "            out, self.hidden_state = self.lstm(x, self.hidden_state)\n",
    "        else:\n",
    "            out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        return self.fc(out)\n",
    "\n",
    "# ==============================\n",
    "# 4Ô∏è‚É£ ‡∏™‡∏£‡πâ‡∏≤‡∏á dataset ‡∏à‡∏≤‡∏Å RC_Tank\n",
    "# ==============================\n",
    "DT = 0.01\n",
    "env = RC_Tank_Env(control_mode='current', max_action_volt=24, level_max=24, dt=DT)\n",
    "sg = SignalGenerator(t_end=1000, dt=DT)  # ‡∏•‡∏î t_end ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö train ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "_, signal = sg.pwm(amplitude=1.0, freq=0.01, duty=0.5)\n",
    "\n",
    "state_list, action_list, next_state_list = [], [], []\n",
    "\n",
    "s, _ = env.reset(default=0.0)\n",
    "for a in signal:\n",
    "    action = a * env.max_action_volt\n",
    "    s_next, _ = env.step(action)\n",
    "    state_list.append([s])\n",
    "    action_list.append([action])\n",
    "    next_state_list.append([s_next])\n",
    "    s = s_next\n",
    "\n",
    "# normalize input/output\n",
    "state_array = np.array(state_list) / env.level_max\n",
    "action_array = np.array(action_list) / env.max_action_volt\n",
    "next_state_array = np.array(next_state_list) / env.level_max\n",
    "\n",
    "X = torch.tensor(np.hstack([state_array, action_array]), dtype=torch.float32).unsqueeze(1)\n",
    "y = torch.tensor(state_array, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ==============================\n",
    "# 5Ô∏è‚É£ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞ train DeepLSTMRegressor\n",
    "# ==============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DeepLSTMRegressor(input_size=2, hidden_size=128, output_size=1, fc_units=[128,64], stateful=True).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "loss_list = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for xb, yb in dataloader:\n",
    "        batch_size = xb.size(0)\n",
    "        model.reset_state(batch_size=batch_size, device=device)  # ‚ö° reset hidden state ‡∏ï‡∏≤‡∏° batch size\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        model.detach_state()  # ‚ö° detach state ‡∏´‡∏•‡∏±‡∏á batch ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ backprop ‡∏Ç‡πâ‡∏≤‡∏° batch\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    loss_list.append(avg_loss)\n",
    "    if epoch % 5 ==0:\n",
    "        print(f\"Epoch {epoch+1}, Loss={avg_loss:.6f}\")\n",
    "\n",
    "# ==============================\n",
    "# 6Ô∏è‚É£ ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö prediction ‡∏Å‡∏±‡∏ö RC_Tank output\n",
    "# ==============================\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model.reset_state(batch_size=X.size(0), device=device)\n",
    "    y_pred = model(X.to(device)).cpu().numpy().flatten() * env.level_max  # denormalize\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(np.arange(len(next_state_list)), np.array(next_state_list).flatten(), label='RC_Tank_Env Output')\n",
    "plt.plot(np.arange(len(y_pred)), y_pred, label='DeepLSTMRegressor Prediction', alpha=0.7)\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Level\")\n",
    "plt.title(\"RC Tank vs DeepLSTMRegressor Prediction\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# üîπ Denormalize true values\n",
    "y_true = np.array(next_state_list).flatten()\n",
    "\n",
    "# üîπ Compute metrics\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\nüìä Model Evaluation Metrics\")\n",
    "print(f\" - MSE  : {mse:.6f}\")\n",
    "print(f\" - RMSE : {rmse:.6f}\")\n",
    "print(f\" - MAE  : {mae:.6f}\")\n",
    "print(f\" - R¬≤    : {r2:.6f}\")\n",
    "\n",
    "# üîπ Plot residuals\n",
    "residuals = y_true - y_pred\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(residuals, label='Residual (True - Pred)', color='orange')\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.xlabel(\"Time step\")\n",
    "plt.ylabel(\"Residual (Error)\")\n",
    "plt.title(\"Residual Analysis of DeepLSTMRegressor\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# üîπ Histogram of residuals\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(residuals, bins=40, color='teal', alpha=0.7)\n",
    "plt.title(\"Distribution of Residuals\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a067b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import pprint # ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏¥‡∏°‡∏û‡πå dictionary ‡∏™‡∏ß‡∏¢‡πÜ\n",
    "\n",
    "# 1. ‡∏£‡∏∞‡∏ö‡∏∏‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
    "# -------------------------------------\n",
    "# ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô path ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå lstm_model.pth ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
    "\n",
    "MODEL_PATH = Path(r\"D:\\Project_end\\New_world\\my_project\\models\\lstm_model_20_s.pth\")\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "if not MODEL_PATH.exists():\n",
    "    print(f\"‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà {MODEL_PATH}\")\n",
    "else:\n",
    "    print(f\"‚úÖ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå checkpoint ‡∏à‡∏≤‡∏Å: {MODEL_PATH}\\n\")\n",
    "\n",
    "    # 2. ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå checkpoint\n",
    "    # -------------------------------------\n",
    "    # ‡πÉ‡∏ä‡πâ map_location='cpu' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏î‡πâ ‡πÅ‡∏°‡πâ‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ GPU\n",
    "    # MODIFIED: ‡πÄ‡∏û‡∏¥‡πà‡∏° weights_only=False ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î‡∏≠‡πá‡∏≠‡∏ö‡πÄ‡∏à‡∏Å‡∏ï‡πå Python ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å weights\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=torch.device('cpu'), weights_only=False)\n",
    "\n",
    "    # 3. ‡πÅ‡∏™‡∏î‡∏á Key ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô checkpoint\n",
    "    # -------------------------------------\n",
    "    print(\"üîë Keys ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô Checkpoint:\")\n",
    "    print(\"-\" * 30)\n",
    "    # ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ pprint ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÑ‡∏î‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "    pprint.pprint(list(checkpoint.keys()))\n",
    "    print(\"-\" * 30, \"\\n\")\n",
    "\n",
    "\n",
    "    # 4. ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô\n",
    "    # -------------------------------------\n",
    "    print(\"üîç ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"   - Model Type: {checkpoint.get('model_type', 'N/A')}\")\n",
    "    print(f\"   - Learning Rate: {checkpoint.get('learning_rate', 'N/A')}\")\n",
    "    print(f\"   - Batch Size: {checkpoint.get('batch_size', 'N/A')}\")\n",
    "    print(f\"   - Sequence Size: {checkpoint.get('sequence_size', 'N/A')}\")\n",
    "    print(f\"   - Torch Version: {checkpoint.get('torch_version', 'N/A')}\")\n",
    "    print(f\"   - Timestamp: {checkpoint.get('timestamp', 'N/A')}\")\n",
    "    print(f\"   - Path to Scaling Zip: {checkpoint.get('scaling_zip', 'N/A')}\")\n",
    "\n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• loss ‡∏Ç‡∏≠‡∏á epoch ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢\n",
    "    train_losses = checkpoint.get('train_losses', [])\n",
    "    if train_losses:\n",
    "        print(f\"   - Final Training Loss: {train_losses[-1]:.6f} (‡∏à‡∏≤‡∏Å {len(train_losses)} epochs)\")\n",
    "\n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata ‡∏Ç‡∏≠‡∏á scaler\n",
    "    scaler_metadata = checkpoint.get('scaler_metadata')\n",
    "    if scaler_metadata:\n",
    "        print(\"\\nüìÑ Scaler Metadata:\")\n",
    "        pprint.pprint(scaler_metadata)\n",
    "\n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á model_state_dict (‡∏î‡∏π‡πÅ‡∏Ñ‡πà layer ‡πÅ‡∏£‡∏Å‡πÜ)\n",
    "    model_state = checkpoint.get('model_state_dict')\n",
    "    if model_state:\n",
    "        print(\"\\nüß† ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Model State (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á):\")\n",
    "        for i, (name, param) in enumerate(model_state.items()):\n",
    "            print(f\"   - Layer: {name},   Shape: {param.shape}\")\n",
    "            if i >= 4: # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà 5 layers ‡πÅ‡∏£‡∏Å‡∏û‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á\n",
    "                print(\"     ...\")\n",
    "                break\n",
    "    print(\"-\" * 30)\n",
    "    for k, v in checkpoint.items():\n",
    "        if isinstance(v, (int, float, str)):\n",
    "            print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba9d8497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TIME', 'DATA_INPUT', 'DATA_OUTPUT']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "file_path = Path(r\"D:\\Project_end\\New_world\\my_project\\data\\raw\\pwm_duty_0.50_freq_0.01_pwm_amplitude_1_freq_0.01_duty_0.5.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba2c1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# LSTM Inference from Real CSV (Autoregressive Sequence Inference)\n",
    "# (Enhanced version with auto scaler loading and feature matching)\n",
    "# ==============================================================\n",
    "\n",
    "%run setup_path.py\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from src.models.lstm_model import VanillaLSTM_MODEL, DeepLSTM_MODEL, BiLSTM_MODEL\n",
    "from src.data.scaling_loader import ScalingZipLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# ==============================================================\n",
    "# 1. Load model checkpoint\n",
    "# ==============================================================\n",
    "MODEL_PATH = Path(r\"D:\\Project_end\\New_world\\my_project\\models\\lstm_model_2_s.pth\")\n",
    "CSV_PATH = Path(r\"D:\\Project_end\\New_world\\my_project\\data\\raw\\pwm_duty_0.80_freq_0.10_pwm_amplitude_1_freq_0.1_duty_0.8.csv\")\n",
    "SCALER_PATH = Path(r\"D:\\Project_end\\New_world\\my_project\\config\\Test1_scalers.zip\")\n",
    "\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=torch.device(\"cpu\"), weights_only=False)\n",
    "print(\"‚úÖ Loaded checkpoint from:\", MODEL_PATH)\n",
    "\n",
    "# ==============================================================\n",
    "# 2. Extract model configuration\n",
    "# ==============================================================\n",
    "model_type = checkpoint.get(\"model_type\", \"DeepLSTM\")\n",
    "input_dim = checkpoint[\"input_dim\"]\n",
    "output_dim = checkpoint[\"output_dim\"]\n",
    "hidden_dim = checkpoint[\"hidden_dim\"]\n",
    "num_layers = checkpoint[\"num_layers\"]\n",
    "sequence_size = checkpoint.get(\"sequence_size\", 50)\n",
    "fc_units = checkpoint.get(\"fc_units\", [64, 32])\n",
    "\n",
    "print(f\"üß† Model Info:\\n\"\n",
    "      f\"   Type = {model_type}\\n\"\n",
    "      f\"   Input dim = {input_dim}, Hidden dim = {hidden_dim}, Output dim = {output_dim}\\n\"\n",
    "      f\"   Num layers = {num_layers}, Sequence size = {sequence_size}, FC units = {fc_units}\")\n",
    "\n",
    "# ==============================================================\n",
    "# 3. Rebuild model\n",
    "# ==============================================================\n",
    "if model_type == \"VanillaLSTM\":\n",
    "    model = VanillaLSTM_MODEL(input_dim, hidden_dim, num_layers, output_dim, fc_units=fc_units)\n",
    "elif model_type == \"DeepLSTM\":\n",
    "    model = DeepLSTM_MODEL(input_dim, hidden_dim, num_layers, output_dim, fc_units=fc_units)\n",
    "elif model_type == \"BiLSTM\":\n",
    "    model = BiLSTM_MODEL(input_dim, hidden_dim, num_layers, output_dim, fc_units=fc_units)\n",
    "else:\n",
    "    raise ValueError(f\"‚ùå Unknown model type: {model_type}\")\n",
    "\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"], strict=False)\n",
    "model.eval()\n",
    "print(\"‚úÖ Model ready for inference\")\n",
    "\n",
    "# ==============================================================\n",
    "# 4. Load Scalers (Auto detect ZIP or PKL + Feature Alignment)\n",
    "# ==============================================================\n",
    "def load_scalers_auto(path: Path):\n",
    "    if str(path).endswith(\".zip\"):\n",
    "        print(\"üì¶ Detected ZIP scaler ‚Üí using ScalingZipLoader\")\n",
    "        loader = ScalingZipLoader(path)\n",
    "        scaler_x, scaler_y = loader.scaler_in, loader.scaler_out\n",
    "        input_features = getattr(loader, \"input_features\", [\"DATA_INPUT\", \"DATA_OUTPUT\"])\n",
    "        output_features = getattr(loader, \"output_features\", [\"DATA_OUTPUT\"])\n",
    "    elif str(path).endswith(\".pkl\"):\n",
    "        print(\"üì¶ Detected PKL scaler ‚Üí using joblib.load()\")\n",
    "        data = joblib.load(path)\n",
    "        scaler_x = data.get(\"input_scaler\", data.get(\"scaler_in\"))\n",
    "        scaler_y = data.get(\"output_scaler\", data.get(\"scaler_out\"))\n",
    "        input_features = data.get(\"input_features\", [\"DATA_INPUT\", \"DATA_OUTPUT\"])\n",
    "        output_features = data.get(\"output_features\", [\"DATA_OUTPUT\"])\n",
    "    else:\n",
    "        raise ValueError(\"‚ùå Unsupported scaler format. Must be .zip or .pkl\")\n",
    "    return scaler_x, scaler_y, input_features, output_features\n",
    "\n",
    "scaler_x, scaler_y, input_features, output_features = load_scalers_auto(SCALER_PATH)\n",
    "print(\"‚úÖ Loaded scalers successfully with features:\", input_features)\n",
    "\n",
    "# ==============================================================\n",
    "# 5. Load CSV signal data\n",
    "# ==============================================================\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "if not any(\"INPUT\" in c.upper() for c in df.columns):\n",
    "    raise KeyError(\"‚ùå CSV must contain at least one input column (e.g., 'DATA_INPUT')\")\n",
    "\n",
    "input_col = [c for c in df.columns if \"INPUT\" in c.upper()][0]\n",
    "output_col = [c for c in df.columns if \"OUTPUT\" in c.upper()][0]\n",
    "\n",
    "u_signal = df[input_col].values\n",
    "y_true = df[output_col].values\n",
    "t = np.arange(len(u_signal)) * 0.1\n",
    "\n",
    "# ==============================================================\n",
    "# 6. Autoregressive Inference (Auto Feature Matching)\n",
    "# ==============================================================\n",
    "seq_len = sequence_size\n",
    "y_preds = []\n",
    "buffer_y = list(y_true[:seq_len])\n",
    "buffer_u = list(u_signal[:seq_len])\n",
    "\n",
    "for i in range(seq_len, len(u_signal)):\n",
    "    seq_data = []\n",
    "    for name in input_features:\n",
    "        if \"INPUT\" in name.upper():\n",
    "            seq_data.append(buffer_u[-seq_len:])\n",
    "        elif \"OUTPUT\" in name.upper() or \"Y\" in name.upper():\n",
    "            seq_data.append(buffer_y[-seq_len:])\n",
    "        else:\n",
    "            seq_data.append(np.zeros(seq_len))  # unknown features = 0\n",
    "\n",
    "    seq_input = pd.DataFrame(np.column_stack(seq_data), columns=input_features)\n",
    "\n",
    "    # --- Apply scaler transformation ---\n",
    "    try:\n",
    "        x_scaled = scaler_x.transform(seq_input)\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Fallback: using partial columns match\")\n",
    "        valid_cols = [c for c in seq_input.columns if c in getattr(scaler_x, \"feature_names_in_\", seq_input.columns)]\n",
    "        x_scaled = scaler_x.transform(seq_input[valid_cols])\n",
    "\n",
    "    # --- Predict ---\n",
    "    x_tensor = torch.tensor(x_scaled[np.newaxis, :, :], dtype=torch.float32)\n",
    "    if x_tensor.shape[-1] != input_dim:\n",
    "        # Auto-fix dimension mismatch by trimming or padding\n",
    "        diff = input_dim - x_tensor.shape[-1]\n",
    "        if diff > 0:\n",
    "            pad = torch.zeros((1, seq_len, diff))\n",
    "            x_tensor = torch.cat([x_tensor, pad], dim=-1)\n",
    "        elif diff < 0:\n",
    "            x_tensor = x_tensor[:, :, :input_dim]\n",
    "        print(f\"‚öôÔ∏è Auto adjusted input dim to {x_tensor.shape[-1]} (expected {input_dim})\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_scaled = model(x_tensor)\n",
    "        y_next = scaler_y.inverse_transform(y_scaled.numpy())[0, 0]\n",
    "\n",
    "    y_preds.append(y_next)\n",
    "    buffer_y.append(y_next)\n",
    "    buffer_u.append(u_signal[i])\n",
    "\n",
    "y_preds = np.array(y_preds)\n",
    "y_true_eval = y_true[seq_len:]\n",
    "t_eval = t[seq_len:]\n",
    "\n",
    "# ==============================================================\n",
    "# 7. Visualization\n",
    "# ==============================================================\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(t_eval, y_true_eval, label=\"Measured Output (y_true)\", color=\"blue\", alpha=0.6)\n",
    "plt.plot(t_eval, y_preds, label=\"Predicted Output (≈∑_t)\", color=\"red\", linewidth=2)\n",
    "plt.plot(t, u_signal, label=\"Input (u_t)\", color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "plt.title(\"Autoregressive LSTM Inference with Temporal Context\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude / Response\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==============================================================\n",
    "# 8. Evaluation Metrics\n",
    "# ==============================================================\n",
    "mse = mean_squared_error(y_true_eval, y_preds)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_true_eval, y_preds)\n",
    "r2 = r2_score(y_true_eval, y_preds)\n",
    "\n",
    "print(\"\\nüìä Model Evaluation Results\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(f\"üìè MSE  (Mean Squared Error):      {mse:.6f}\")\n",
    "print(f\"üìè RMSE (Root Mean Squared Error): {rmse:.6f}\")\n",
    "print(f\"üìè MAE  (Mean Absolute Error):     {mae:.6f}\")\n",
    "print(f\"üìà R¬≤   (Coefficient of Determination): {r2:.6f}\")\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "# Residuals\n",
    "residuals = y_true_eval - y_preds\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(residuals, bins=40, color=\"purple\", alpha=0.6)\n",
    "plt.title(\"Residual Distribution (y_true - y_pred)\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NEW_WORLD_SETUP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
